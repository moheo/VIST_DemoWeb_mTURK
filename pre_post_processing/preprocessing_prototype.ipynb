{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pickle as pkl\n",
    "import os "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'dict'>\n",
      "25275\n"
     ]
    }
   ],
   "source": [
    "with open('test.story-in-sequence.json', 'rb') as f_test_sis:\n",
    "    test_sis = json.load(f_test_sis)\n",
    "    print(type(test_sis))\n",
    "    print(len(test_sis['annotations']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('test.storyid2photos_list.json', 'rb') as s2p:\n",
    "    s2p_dict = json.load(s2p)\n",
    "\n",
    "#inspect here\n",
    "for storyid in s2p_dict:\n",
    "    target = s2p_dict[storyid]\n",
    "    \n",
    "    for entry in s2p_dict:\n",
    "        if target == s2p_dict: \n",
    "            print(\"for\", storyid)\n",
    "            print(entry, \"is duplicate\") # no duplicates in testset photostream!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5055.0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "25275/5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 45530 : the local parish holds a craft show each year .\n",
      "1 45530 : lots of folks come out and set up tables to sell their crafts .\n",
      "2 45530 : some of these crafts are very unique and take a lot of talent to make .\n",
      "3 45530 : folks of all ages come out to peruse the crafts for sale .\n",
      "4 45530 : some of the crafters even dress up in unique costumes as part of their selling act .\n",
      "0 45531 : i was so excited to be heading to the crafts fair .\n",
      "1 45531 : when i arrived i saw a great booth with a variety of great crafts .\n",
      "2 45531 : i stopped at chatted at my friend [female] 's booth for a bit .\n",
      "3 45531 : there were even booths set up for all of the kids .\n",
      "4 45531 : i found some awesome crafts at the fair , i 'm really happy that i went .\n"
     ]
    }
   ],
   "source": [
    "for entity in test_sis['annotations'][:10]:\n",
    "    print(entity[0]['worker_arranged_photo_order'], entity[0]['story_id'], \":\", entity[0]['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'We had a great view of Minute Maid Park from our hotel room.'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_sis['annotations'][29*5][0]['original_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_sis['annotations'][31][0]['worker_arranged_photo_order']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def storyID2norm_txt(test_sis_annot):\n",
    "    storyID2norm_txt = {}\n",
    "    storyID = test_sis_annot[0][0]['story_id'] #init storyID\n",
    "    sen_list = []\n",
    "    for entity in test_sis_annot:\n",
    "        if storyID != entity[0]['story_id']:\n",
    "            #add to dict\n",
    "            norm_txt = \" \".join(sen_list) # concat sentences in the list with whitespace as a delim\n",
    "            storyID2norm_txt[storyID] =  norm_txt\n",
    "            #renew sid, sen_list\n",
    "            storyID = entity[0]['story_id'] \n",
    "            sen_list = [] \n",
    "        #general behavior for gathering sentences \n",
    "        sentence = entity[0]['text']    \n",
    "        sen_list.append(sentence) \n",
    "    return storyID2norm_txt\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def what_storyID(ps, s2p_dict): # working good \n",
    "    index = list(s2p_dict.values()).index(ps) # if there is no ps in the values, it raises error \"ps is not in the list\"\n",
    "    story_id = list(s2p_dict.keys())[index] \n",
    "    \n",
    "    return story_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# s2nt_dict is dict with 5054 entries (testset as a whole)\n",
    "s2nt_dict = storyID2norm_txt(test_sis['annotations']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"new_test.storyid2txt.json\", \"w\") as f: #json dump supports str so you need to use w rather than wb \n",
    "    json.dump(s2nt_dict,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parses html names into photoids, and make list of lists with each of them includes 5 photos\n",
    "def htmls2ps(htmldir):\n",
    "    ps_list = []\n",
    "    for html_name in os.listdir(htmldir):\n",
    "        splited = html_name.split('-')\n",
    "        ps = splited[:5]\n",
    "        ps_list.append(ps)\n",
    "    return ps_list\n",
    "\n",
    "\n",
    "# returns storyids from unique ps. \n",
    "### note that if you are targeting storyIDs sharing the same photosequence it wouldnt work as you expects\n",
    "### 200 htmls has 200 distinct ps's thus it's ok to use it.\n",
    "def get_storyid_from_htmls(htmldir,s2p_dict):\n",
    "    html_sid_list = []\n",
    "    ps_list = htmls2ps(htmldir) # make ps_list (that is shape of (200 , 5) in pytorch style)\n",
    "    for ps in ps_list: # check whether ps in ps_list is in testset \n",
    "        sid = what_storyID(ps, s2p_dict)\n",
    "        html_sid_list.append(sid)\n",
    "    return html_sid_list \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "htmldir = \"/home/seonils/data_storage/vist200web/www\"\n",
    "html_storyids_list = get_storyid_from_htmls(htmldir,s2p_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# returns 200 html storyID: [pid0, pid1, pid2, pid3, pid4] formed dict\n",
    "def html_sids2ps_n_nt(html_storyids_list, s2p_dict, s2nt_dict):\n",
    "    html_sids2ps_dict = {}\n",
    "    html_sids2nt_dict = {} \n",
    "    for sid in html_storyids_list:\n",
    "        html_sids2ps_dict[sid] = s2p_dict[sid]\n",
    "        html_sids2nt_dict[sid] = s2nt_dict[sid]\n",
    "    return html_sids2ps_dict, html_sids2nt_dict "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "h_sid2ps, h_sid2nt = html_sids2ps_n_nt(html_storyids, s2p_dict, s2nt_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"200html_sid2photostream.json\", \"w\")  as ps_f, open(\"200html_sid2norm_txt.json\", \"w\") as nt_f:\n",
    "    json.dump(h_sid2ps, ps_f)\n",
    "    json.dump(h_sid2nt, nt_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"SnuBiVtt1_298.json\", \"r\") as f:\n",
    "    glacnet_dict = json.load(f)\n",
    "    #print(type(model_out))\n",
    "    #print(model_out.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['photo_sequence', 'album_id', 'story_text_normalized'])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glacnet_dict['output_stories'][0].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def modelout_sid2normtxt(html_storyids, modelout_dict, h_sid2ps):\n",
    "    modelout_sid2normtxt = {}\n",
    "    for sid in html_storyids:\n",
    "        ps = h_sid2ps[sid]\n",
    "        for entry in modelout_dict['output_stories']:\n",
    "            if ps == entry['photo_sequence']:\n",
    "                modelout_sid2normtxt[sid] = entry['story_text_normalized']\n",
    "    return modelout_sid2normtxt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "glacnet_normtxt = modelout_sid2normtxt(html_storyids, glacnet_dict, h_sid2ps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(glacnet_normtxt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"200_glacnet_normtxt.json\", \"w\") as f:\n",
    "    json.dump(glacnet_normtxt,f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# from here we split any model output into 10 pieces  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "keyslist = list(h_sid2nt.keys())\n",
    "#glac = json.load(open(\"200_glacnet_normtxt.json\",'r')).keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(keyslist) == sorted(list(glac)) #휴유가 네지.... 다른 줄 알았다.\n",
    "sorted(keyslist) == keyslist # sorted returns \"new\" sorted list. do not work \"in-place\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "keysplits = [keyslist[20*i:20*(i+1)] for i in range(10)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "human_dicts10_list = []\n",
    "for keys in keysplits: # keys = [pid0 ~ 4]\n",
    "    stories = [h_sid2nt[key] for key in keys] # key = pid itself\n",
    "    human_dicts10_list.append(dict(zip(keys,stories))) # dict,zip returns len=20 dict. list of 10 (splited, len20) dicts\n",
    "\n",
    "#glac_dicts10_idx = dict(zip(range(10), glac_dicts10_list))\n",
    "#print(glac_dicts10_idx.keys())\n",
    "for i in range(10):\n",
    "    if i == 0: os.mkdir(\"/home/seonils/data_storage/VIST_DemoWeb_mTURK/webstorm_server/data/human_splits\")\n",
    "    with open(\"../webstorm_server/data/human_splits/human_normtxt_spl_{}.json\".format(i), \"w\") as f:\n",
    "        json.dump(human_dicts10_list[i], f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = [json.load(open('../webstorm_server/data/human_splits/human_normtxt_spl_{}.json'.format(i), 'r')) for i in range(10)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "20\n",
      "True\n",
      "20\n",
      "True\n",
      "20\n",
      "True\n",
      "20\n",
      "True\n",
      "20\n",
      "True\n",
      "20\n",
      "True\n",
      "20\n",
      "True\n",
      "20\n",
      "True\n",
      "20\n"
     ]
    }
   ],
   "source": [
    "for i in range(1,10):\n",
    "    print(sorted(a[0].values()) != sorted(a[i].values()))\n",
    "    print(len(set(list(a[i]))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ab', '']"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"abcde\".split(\"cde\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:dl]",
   "language": "python",
   "name": "conda-env-dl-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
